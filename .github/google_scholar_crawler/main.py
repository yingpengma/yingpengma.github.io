import requests
import json
import os
from datetime import datetime

def get_scholar_data():
    """ä½¿ç”¨SerpAPIè·å–Google Scholaræ•°æ®"""
    api_key = os.environ['SERPAPI_KEY']
    scholar_id = 'Qrghm1QAAAAJ'  # ç›´æ¥ç¡¬ç¼–ç ï¼Œæ— éœ€secret
    
    # SerpAPIè¯·æ±‚å‚æ•°
    params = {
        'engine': 'google_scholar_author',
        'author_id': scholar_id,
        'api_key': api_key,
        'hl': 'en'
    }
    
    print(f"ğŸ” æ­£åœ¨è·å–Google Scholaræ•°æ® (ID: {scholar_id})")
    
    response = requests.get('https://serpapi.com/search', params=params, timeout=60)
    
    if response.status_code != 200:
        raise Exception(f"SerpAPIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
    
    data = response.json()
    
    if 'error' in data:
        raise Exception(f"SerpAPIé”™è¯¯: {data['error']}")
    
    # æå–ä½œè€…ä¿¡æ¯
    author = data.get('author', {})
    name = author.get('name', '')
    
    # æå–å¼•ç”¨ç»Ÿè®¡
    cited_by = data.get('cited_by', {})
    total_citations = 0
    
    if 'table' in cited_by and cited_by['table']:
        # ä»tableä¸­æå–æ€»å¼•ç”¨æ•°
        for item in cited_by['table']:
            if 'citations' in item:
                total_citations = item['citations'].get('all', 0)
                break
    
    # æå–è®ºæ–‡åˆ—è¡¨
    articles = data.get('articles', [])
    publications = {}
    
    for article in articles:
        citation_id = article.get('citation_id', '')
        if citation_id:
            publications[citation_id] = {
                'author_pub_id': citation_id,
                'title': article.get('title', ''),
                'num_citations': article.get('cited_by', {}).get('value', 0),
                'year': article.get('year', ''),
                'authors': article.get('authors', ''),
                'publication': article.get('publication', '')
            }
    
    # æ„å»ºå…¼å®¹æ ¼å¼çš„æ•°æ®ç»“æ„
    result = {
        'name': name,
        'citedby': total_citations,
        'publications': publications,
        'updated': str(datetime.now()),
        'affiliations': author.get('affiliations', ''),
        'email': author.get('email', ''),
        'interests': author.get('interests', [])
    }
    
    return result

def save_data():
    """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
    os.makedirs('results', exist_ok=True)
    
    data = get_scholar_data()
    
    print(f"âœ… è·å–æˆåŠŸ:")
    print(f"   - å§“å: {data['name']}")
    print(f"   - æ€»å¼•ç”¨æ•°: {data['citedby']}")
    print(f"   - è®ºæ–‡æ•°é‡: {len(data['publications'])}")
    
    # ä¿å­˜è¯¦ç»†æ•°æ®
    with open('results/gs_data.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜shields.ioæ ¼å¼æ•°æ®
    shields_data = {
        "schemaVersion": 1,
        "label": "citations",
        "message": f"{data['citedby']}"
    }
    
    with open('results/gs_data_shieldsio.json', 'w', encoding='utf-8') as f:
        json.dump(shields_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ° results/ ç›®å½•")

if __name__ == "__main__":
    try:
        save_data()
        print("ğŸ‰ ä»»åŠ¡æˆåŠŸå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        exit(1) 